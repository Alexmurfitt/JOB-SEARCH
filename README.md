# ğŸ” SEARCH_JOB â€“ Sistema Inteligente de ExtracciÃ³n y ClasificaciÃ³n de Empleo

`SEARCH_JOB` es una plataforma de anÃ¡lisis inteligente diseÃ±ada para **extraer, procesar, analizar y clasificar ofertas de empleo** desde mÃºltiples fuentes web, con el objetivo de generar conocimiento estructurado y detectar patrones relevantes del mercado laboral. Este sistema combina **scraping, procesamiento lingÃ¼Ã­stico, modelado machine learning y visualizaciÃ³n de datos**, todo orquestado en una arquitectura modular y escalable.

---

## ğŸ“Œ Objetivos principales

- Automatizar la extracciÃ³n de ofertas de empleo de mÃºltiples portales web.
- Limpiar, transformar y estandarizar la informaciÃ³n.
- Detectar y etiquetar entidades clave (tÃ­tulo, salario, empresa, ubicaciÃ³n, tecnologÃ­as, etc.).
- Clasificar las ofertas segÃºn distintos modelos (ej. NLP, catboost).
- Visualizar insights relevantes y exportar reportes.
- Guardar la informaciÃ³n estructurada en una base de datos relacional PostgreSQL.

---

## âš™ï¸ TecnologÃ­as y herramientas utilizadas

| CategorÃ­a | Herramientas |
|----------|--------------|
| Lenguaje principal | `Python 3.12` |
| Scraping | `Scrapy`, `requests`, `BeautifulSoup` |
| Procesamiento de texto | `spaCy`, `NLTK`, `re` |
| Modelado ML | `CatBoost`, `Scikit-learn`, `Joblib` |
| VisualizaciÃ³n | `Matplotlib`, `Seaborn`, `Plotly`, `PDF` |
| Base de datos | `PostgreSQL`, `psycopg2` |
| Entorno virtual | `venv_jobs` |
| Control de versiones | `Git`, `.gitignore` |
| OrganizaciÃ³n | `scripts/`, `models/`, `data/`, `reports/`, `config/`, `docs/` |
| Infraestructura | `.env` para credenciales, carpetas excluidas con `.gitignore` |

---

## ğŸ§± Estructura del proyecto

```
SEARCH_JOB/
â”œâ”€â”€ .github/                      # Workflows o acciones automatizadas
â”œâ”€â”€ .gitignore                   # Exclusiones de Git
â”œâ”€â”€ artifacts/                   # Resultados intermedios o modelos
â”œâ”€â”€ config/                      # ConfiguraciÃ³n y scripts de limpieza
â”‚   â””â”€â”€ reorganizar_estructura_jobs.ps1
â”œâ”€â”€ data/                        # Conjuntos de datos estructurados
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”œâ”€â”€ docs/                        # DocumentaciÃ³n tÃ©cnica o referencias
â”œâ”€â”€ img/                         # GrÃ¡ficos usados en informes o presentaciones
â”œâ”€â”€ models/                      # Modelos entrenados y recursos NLP
â”‚   â””â”€â”€ ner_model/, ner_ng/, catboost_info/
â”œâ”€â”€ reports/                     # Informes generados (PDFs, visualizaciones)
â”œâ”€â”€ scripts/                     # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ model_training/
â”‚   â””â”€â”€ analysis/
â”œâ”€â”€ scrapy_employment_scraper/  # Proyecto Scrapy para fuentes web
â”œâ”€â”€ .env                         # Variables de entorno (NO subir a GitHub)
â””â”€â”€ README.md                    # Este archivo
```

---

## ğŸ§  Modelos incluidos

- **NER personalizado (spaCy)**: Reconocimiento de entidades como "Empresa", "TecnologÃ­a", "UbicaciÃ³n", "Salario".
- **CatBoostClassifier**: Modelo entrenado para clasificar ofertas de empleo por sector o tipo de perfil.
- **Reglas heurÃ­sticas y limpieza avanzada**: Para correcciÃ³n de ruido textual y deduplicaciÃ³n.

---

## ğŸš€ EjecuciÃ³n del sistema

1. Clona el repositorio y activa el entorno virtual `venv_jobs`.
2. Crea un archivo `.env` con tus credenciales PostgreSQL:

```env
DB_HOST=localhost
DB_NAME=jobs_db
DB_USER=postgres
DB_PASS=tu_contraseÃ±a
```

3. Ejecuta los mÃ³dulos de scraping desde `scrapy_employment_scraper/`.
4. Lanza el pipeline de limpieza, modelado y anÃ¡lisis desde `scripts/`.

---

## ğŸ“¤ ExportaciÃ³n y visualizaciÃ³n

- Los resultados se exportan a PDF (`reports/`) y se pueden consultar en dashboards personalizados.
- Los modelos y datos se almacenan localmente en `models/` y `data/`.

---

## âŒ Exclusiones importantes (.gitignore)

```bash
# Entornos virtuales
venv_jobs/
.env

# Modelos pesados
models/**/tokenizer.json
models/**/vocab.txt
catboost_info/
*.joblib

# Archivos intermedios o binarios
*.pdf
*.pt
*.tsv
*.tmp
__pycache__/
```

---

## ğŸ“Œ Estado actual del proyecto

ğŸ”§ En fase de consolidaciÃ³n: limpieza de estructura, optimizaciÃ³n del cÃ³digo, documentaciÃ³n final y despliegue remoto.

---

## ğŸ“¬ Contacto

Creado y mantenido por **Alexander Murfitt Santana**.  
GitHub: [@Alexmurfitt](https://github.com/Alexmurfitt)

---

