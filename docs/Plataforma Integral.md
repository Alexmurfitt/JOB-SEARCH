# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
# üìò Proyecto: Plataforma Integral de An√°lisis y Recomendaci√≥n de Formaci√≥n en Ciencia de Datos

## üéØ Objetivos Generales

* **Identificar** formaciones acad√©micas, certificaciones profesionales y habilidades t√©cnicas asociadas a los salarios m√°s altos del mercado global en el rol de *Analista de Datos*.
* **Implementar** un sistema experto de extremo a extremo, desde la recolecci√≥n de datos hasta el an√°lisis predictivo y la visualizaci√≥n de resultados, que permita extraer insights accionables del mercado laboral.
* **Construir** una hoja de ruta formativa personalizada (a corto, medio y largo plazo) para profesionales, estimando el ROI (Retorno de Inversi√≥n) de adquirir nuevas competencias en t√©rminos de aumento salarial.

## üß± Componentes del Sistema (Completados ‚úÖ)

### ‚úÖ Ingesta & Normalizaci√≥n de Datos (Scraping)

* **Scraping multifuente** (LinkedIn, Glassdoor, Indeed, InfoJobs, etc.) realizado con *Scrapy* + *Playwright* para capturar ofertas de empleo de Analista de Datos a gran escala.
* **Parsing y estandarizaci√≥n de salarios:** conversi√≥n de distintos formatos (ej. sueldo por hora, sueldo en USD/anual, rangos salariales) a un valor num√©rico unificado en EUR/a√±o.
* **Enriquecimiento externo:** comparaci√≥n con datos p√∫blicos de benchmarks salariales (ej. Glassdoor, Levels.fyi, Instituto Nacional de Estad√≠stica) para contextualizar las bandas salariales obtenidas.

### ‚úÖ Procesamiento NLP & NER Fine-Tuned

* **Limpieza de texto:** depuraci√≥n de descripciones (eliminaci√≥n de HTML, caracteres especiales, normalizaci√≥n de may√∫sculas/min√∫sculas). Detecci√≥n autom√°tica del idioma y traducci√≥n al espa√±ol o ingl√©s si la oferta est√° en otro idioma, asegurando consistencia ling√º√≠stica.
* **Extracci√≥n de entidades:** uso de *transformers* (modelo BERT fine-tuneado con HuggingFace Trainer) para *Named Entity Recognition* especializado, extrayendo menciones de skills t√©cnicas, herramientas, formaciones acad√©micas, certificaciones e idiomas en los textos de las ofertas.
* **Clasificaci√≥n sem√°ntica:** categorizaci√≥n multiclase de cada entidad detectada en su tipo (por ejemplo, distinguir Python como *skill*, un *M√°ster* como formaci√≥n acad√©mica, TOEFL como *certificaci√≥n*, etc.), permitiendo estructurar la informaci√≥n de manera uniforme.

### ‚úÖ Dataset Estructurado & *Feature Engineering*

* **Generaci√≥n de variables:** construcci√≥n de variables *dummy* (binarias) indicando la presencia o ausencia de cada skill/certificaci√≥n relevante en la oferta, variables continuas (ej. a√±os de experiencia si se infieren, tama√±o de la empresa si se dispone, etc.) y variables contextuales (ubicaci√≥n, seniority del puesto, tipo de contrato).
* **Columnas sem√°nticas unificadas:** normalizaci√≥n de nombres de tecnolog√≠as y t√≠tulos formativos para evitar duplicados (ej. unificar ‚ÄúMachine Learning‚Äù vs ‚ÄúMachineLearning‚Äù en una √∫nica feature). Tambi√©n se incorporan representaciones num√©ricas de texto (vectorizaci√≥n TF-IDF de descripciones, si es √∫til) para capturar informaci√≥n adicional.
* **Dataset final listo para modelado:** integraci√≥n de todas las fuentes y variables en una tabla consolidada, donde cada fila representa una oferta de empleo con sus features y la variable objetivo *salario*. Este dataset balancea las distintas fuentes de datos y se guarda para su uso en la fase de modelado.

### ‚úÖ Modelado Predictivo

* **Algoritmos utilizados:** entrenamiento de m√∫ltiples modelos de Machine Learning para regresi√≥n salarial, incluyendo Random Forest, XGBoost, LightGBM, CatBoost e incluso redes neuronales profundas (*PyTorch/TensorFlow*), para encontrar la mejor capacidad predictiva.
* **Optimizaci√≥n y *ensemble***: ajuste de hiperpar√°metros automatizado con *Optuna* y validaci√≥n cruzada anidada (*Nested CV*) para evitar overfitting. Se implementa un *Stacking Ensemble* combinando los mejores modelos individuales, logrando mayor precisi√≥n (error MAE < 5 % en validaci√≥n).
* **Benchmark con NLP puro:** adem√°s del enfoque basado en features estructuradas, se entren√≥ un modelo de regresi√≥n usando directamente *BERT fine-tuned* sobre las descripciones completas de las ofertas para comparar desempe√±o, asegurando que el enfoque estructurado sea competitivo.

### ‚úÖ Interpretabilidad & Explicaciones

* **SHAP values (SHapley Additive exPlanations):** an√°lisis global y local de importancia de features. Se calcula la contribuci√≥n de cada skill, certificaci√≥n o formaci√≥n al salario predicho, identificando las variables m√°s influyentes positivamente o negativamente en la remuneraci√≥n.
* **Narrativas autom√°ticas:** generaci√≥n de textos interpretativos que resumen hallazgos (por ejemplo, ‚ÄúConocer X y Y aporta un incremento estimado de Z ‚Ç¨ en el salario‚Äù) para comunicar insights a usuarios no t√©cnicos. Estas explicaciones se integran tanto en el informe PDF como en el dashboard.

### ‚úÖ Dashboard & Visualizaci√≥n

* **Aplicaci√≥n interactiva:** desarrollo de un dashboard en Streamlit con gr√°ficos din√°micos (Plotly, Seaborn) para explorar los resultados. El usuario puede filtrar ofertas por skills, certificaciones o nivel de estudios y visualizar c√≥mo esos filtros afectan a la distribuci√≥n salarial.
* **Simulador de perfil:** m√≥dulo dentro del dashboard que permite ingresar un perfil hipot√©tico (conjunto de habilidades y certificaciones) y obtener el salario proyectado para dicho perfil, compar√°ndolo con la media de mercado. Esto sirve como orientaci√≥n al usuario sobre c√≥mo su perfil se sit√∫a respecto al mercado.
* **Alertas automatizadas:** configuraci√≥n de notificaciones (v√≠a email/Slack) que se activan si se detectan cambios significativos (> 10 %) en el salario promedio de una skill cr√≠tica o una nueva tecnolog√≠a emergente, lo que facilita el seguimiento de tendencias en tiempo real.

### ‚úÖ Reporting Profesional

* **Informes PDF din√°micos:** generaci√≥n de reportes ejecutivos en PDF mediante librer√≠as como FPDF/ReportLab, que resumen los hallazgos clave del an√°lisis. Incluyen gr√°ficos de barras y tablas sobre frecuencia de formaciones (Grado, M√°ster, Doctorado, Certificaciones) en las ofertas y su salario medio asociado, todo actualizado autom√°ticamente con cada ejecuci√≥n del sistema.
* **Automatizaci√≥n con notebooks:** uso de Jupyter notebooks convertidos a PDF/HTML (v√≠a nbconvert) para documentar el proceso de an√°lisis de forma narrativa, integrando texto, c√≥digo y visualizaciones. Esto permite crear informes reproducibles y personalizables para distintas audiencias (RRHH, candidatos, gerencia), con la posibilidad de editar f√°cilmente el contenido antes de la generaci√≥n final.

### ‚úÖ Despliegue & MLOps

* **API RESTful:** implementaci√≥n de un servicio web con FastAPI que expone un endpoint `/predict` para obtener predicciones salariales en tiempo real enviando un perfil JSON (skills, certificaciones, etc.). Esto facilita la integraci√≥n del modelo con otras aplicaciones externas o sistemas internos de RRHH.
* **Contenerizaci√≥n:** creaci√≥n de contenedores Docker para los distintos componentes (scraping, modelo, dashboard, base de datos) asegurando que el sistema sea f√°cilmente portable y escalable en entornos cloud.
* **CI/CD:** pipeline de Integraci√≥n Continua con GitHub Actions para ejecutar tests, *linting* de c√≥digo y despliegues autom√°ticos (por ejemplo, *push* a Docker Hub, despliegue en Heroku/AWS) cada vez que se integra un cambio significativo, garantizando la calidad y la entrega r√°pida de mejoras.
* **Orquestaci√≥n de tareas:** uso de Airflow o Dagster planificado para programar y monitorear el flujo completo de ETL y entrenamiento (por ej., scraping semanal, re-entrenamiento mensual del modelo, regeneraci√≥n de informes), estableciendo un MLOps robusto.
* **Monitorizaci√≥n y retraining:** implementaci√≥n de monitores de data drift y performance del modelo en producci√≥n; si las nuevas predicciones empiezan a perder precisi√≥n debido a cambios en las tendencias (ej. surge una tecnolog√≠a no presente en el entrenamiento original), el sistema alerta o lanza un re-entrenamiento autom√°tico incorporando los nuevos datos.

## üß† Funcionalidades Avanzadas Incorporadas

* **NER sem√°ntico fine-tuned** con un conjunto de datos espec√≠fico de ofertas de trabajo, logrando >95 % F1 en la clasificaci√≥n de entidades clave (menciones de skills, t√≠tulos educativos, etc.). Esto supera la precisi√≥n de modelos gen√©ricos y permite extraer informaci√≥n muy espec√≠fica del dominio.
* **Desambiguaci√≥n de entidades din√°mica:** aplicaci√≥n de t√©cnicas de *clustering* sem√°ntico (embeddings de *Sentence-BERT* + reducci√≥n UMAP + agrupamiento HDBSCAN) para detectar entidades similares escritas de forma distinta. Por ejemplo, agrupar ‚Äúm√°ster en ciencia de datos‚Äù con ‚Äúmaster of science in data science‚Äù como una misma formaci√≥n, limpiando y unificando el dataset autom√°ticamente.
* **Simulaci√≥n de escenarios formativos:** dado un perfil profesional, el sistema puede simular distintos escenarios de mejora formativa. Por ejemplo, se puede calcular cu√°nto aumentar√≠a el salario de un analista si adquiere la certificaci√≥n X o la skill Y, manteniendo todo lo dem√°s constante. Esta simulaci√≥n aprovecha el modelo predictivo para evaluar ROI hipot√©tico de cada formaci√≥n adicional.
* **AutoML h√≠brido:** integraci√≥n experimental de herramientas AutoML (AutoGluon, H2O Driverless AI) para comparar sus resultados con el modelo manual optimizado. Esto garantiza que el enfoque elegido es competitivo y permite descubrir autom√°ticamente combinaciones de features/modelos que pudieran haberse pasado por alto.
* **Vector store + LLM:** preparaci√≥n para incorporar un *vector database* con embeddings de ofertas y perfiles, junto con modelos de lenguaje (GPT-4, etc.), para permitir consultas m√°s inteligentes. Por ejemplo, un usuario podr√≠a preguntar en lenguaje natural ‚Äú¬øQu√© certificaciones me dar√≠an mejor salario en un rol de Data Analyst en Europa?‚Äù y el sistema (apoyado en el vector store y un LLM) comprender√≠a la pregunta y devolver√≠a una recomendaci√≥n fundamentada en los datos.
* **Visi√≥n de grafos de conocimiento:** en el roadmap futuro, se contempla construir un grafo de conocimiento que vincule skills, roles, industrias y salarios, alimentado por nuestros datos. Combinado con aprendizaje federado (para incorporar datos de distintas empresas sin exponer informaci√≥n sensible), esto permitir√° mantener el sistema actualizado de forma colaborativa y ofrecer an√°lisis comparativos entre organizaciones.

## üìà M√©tricas de Precisi√≥n y Rendimiento

* **Precisi√≥n NER personalizada:** >95 % F1 en la identificaci√≥n y clasificaci√≥n de entidades relevantes en las descripciones de puestos (skills, herramientas, t√≠tulos, etc.), validado contra un conjunto de prueba etiquetado manualmente.
* **Error en predicci√≥n salarial:** <5 % de MAE (error absoluto medio) logrado por el modelo predictivo final sobre datos de validaci√≥n, lo que significa que las predicciones de salario difieren en menos del 5 % del valor real en promedio. Esto representa un ajuste muy preciso dada la heterogeneidad de fuentes.
* **Velocidad de inferencia:** < 1 segundo de tiempo de respuesta promedio para una predicci√≥n a trav√©s de la API REST, incluyendo el procesamiento de features del perfil y la inferencia del modelo. Esto permite su uso en aplicaciones en tiempo real sin retrasos apreciables.
* **Cobertura de datos:** Integraci√≥n de **10 plataformas l√≠deres** de empleo a trav√©s del m√≥dulo de scraping, asegurando una cobertura amplia del mercado laboral. El dataset resultante abarca cientos de ofertas √∫nicas, proporcionando una base robusta para el an√°lisis. *(Esta cobertura se expande continuamente a medida que se incorporan nuevas fuentes y se actualizan las existentes.)*

## üèÅ C√≥mo Empezar (Ejecuci√≥n del Flujo)

Para replicar o ejecutar el proyecto en un entorno local, seguir estos pasos:

```bash
# Clonar el repositorio y acceder al directorio del proyecto
git clone <URL-del-repositorio> && cd formacion_salarial_ai

# Crear el entorno virtual e instalar todas las dependencias
make setup          

# Ejecutar el scraping de las plataformas de empleo (resultados en data/raw)
make scrape         

# Procesar los datos brutos: limpieza, NER, clasificaci√≥n sem√°ntica, feature engineering
make preprocess     

# Entrenar modelos de salario y guardar el mejor modelo en /models
make train          

# Iniciar el dashboard de visualizaci√≥n interactiva (Streamlit)
make dashboard      

# (Opcional) Desplegar la API REST (FastAPI) en localhost (requiere Docker)
make deploy         

# Generar el informe PDF autom√°tico con los √∫ltimos resultados
make report         
```

*Nota:* Los comandos anteriores asumen un entorno Unix/Linux con Make. En Windows, puede usarse el script `instalar_entorno_jobs.ps1` para configurar el entorno, y luego ejecutar manualmente los scripts en `scripts/` seg√∫n el orden mostrado. Consulte `requirements.txt` para m√°s detalles de las librer√≠as necesarias.

## üóÇÔ∏è Estructura del Proyecto

A continuaci√≥n se describe la estructura de directorios y archivos principales del proyecto, junto con su prop√≥sito:

* **`job_scraper_advanced/`** ‚Äì Proyecto Scrapy que contiene los *spiders*, *items* y *pipelines* para el web scraping de ofertas. Incluye la configuraci√≥n de *Scrapy Playwright* para renderizar p√°ginas din√°micas. Al ejecutarse, recopila los datos de las distintas webs de empleo y los guarda en archivos JSON/CSV (por ejemplo, `results/jobs.json` o `data/raw/sample_jobs.csv`).
* **`data/`** ‚Äì Carpeta de datos del proyecto:

  * **`data/raw/`** ‚Äì Datos brutos recopilados directamente del scraping, en formato CSV/JSON. Por ejemplo, aqu√≠ se almacena `sample_jobs.csv`, que contiene todas las ofertas de trabajo sin procesar (campos originales de t√≠tulo, compa√±√≠a, ubicaci√≥n, salario tal cual se extrajo, descripci√≥n completa, etc.).
  * **`data/ofertas_variables_semanticas.csv`** ‚Äì Dataset estructurado resultante del procesamiento NLP, con las columnas de features binarias para cada skill/herramienta/certificaci√≥n identificada, adem√°s de columnas limpias de salario y otros campos num√©ricos listos para modelado. Este archivo es generado por el pipeline de preprocesamiento.
* **`models/`** ‚Äì Modelos entrenados y artefactos del pipeline de ML: aqu√≠ se almacenan los archivos resultantes del entrenamiento. Por ejemplo, `salary_predictor.pkl` o `ensemble.joblib` (modelo de regresi√≥n entrenado para predecir salario), junto con objetos auxiliares como el *MultiLabel Binarizer* de skills (`multilabel_skills.pkl`) y gr√°ficos de importancia de features. Estos archivos son cargados posteriormente por la API y el dashboard para hacer predicciones y visualizaciones.
* **`reports/`** ‚Äì Informes generados y figuras: contiene salidas en PDF del sistema de reporting, as√≠ como gr√°ficos y figuras utilizados en dichos informes o en an√°lisis. Por ejemplo, `reports/informe_modelo_salarial.pdf` resume el rendimiento del modelo y `reports/figures/feature_importance.png` podr√≠a ser la gr√°fica de importancia de variables que se incluye en el informe. *(Este directorio es de salida; se crea tras ejecutar los scripts de informes.)*
* **`scripts/`** ‚Äì C√≥digo fuente principal en Python del lado de an√°lisis y aplicaci√≥n:

  * `main_pipeline_jobs.py` ‚Äì Script principal de *preprocesamiento*. Carga los datos crudos del scraping, realiza la limpieza de texto y traducci√≥n, ejecuta el modelo NER para extraer entidades, clasifica dichas entidades en categor√≠as sem√°nticas y construye el dataframe final con todas las features. Finalmente guarda el dataset procesado en `data/ofertas_variables_semanticas.csv`.
  * `analysis_and_modeling_advanced.py` ‚Äì Script de *an√°lisis exploratorio y entrenamiento*. Lee el dataset estructurado, realiza an√°lisis estad√≠sticos (distribuci√≥n de salarios, correlaciones iniciales), y entrena los modelos de Machine Learning para predicci√≥n de salario. Incluye la selecci√≥n y optimizaci√≥n de modelos (p. ej. entrenamiento de varios modelos y combinaci√≥n en un *stacking ensemble*). Al finalizar, guarda el modelo entrenado m√°s preciso en la carpeta `models/` junto con m√©tricas y gr√°ficas (ej.: curva de importancia de variables, comparaci√≥n de MAE entre modelos probados).
  * `dashboard.py` ‚Äì Aplicaci√≥n **Streamlit** para visualizaci√≥n interactiva. Carga los datos estructurados y crudos necesarios, y ofrece una interfaz web con filtros laterales (por skills, certificaciones, educaci√≥n) para filtrar el conjunto de ofertas. Muestra estad√≠sticas clave: n√∫mero de ofertas que cumplen los filtros, distribuci√≥n de salarios para esas ofertas, y gr√°ficos de las skills/certs/formaciones m√°s frecuentes en el subset filtrado. Es la herramienta principal para que usuarios consulten los datos de forma amigable.
  * `app.py` ‚Äì Servicio **FastAPI** para predicci√≥n v√≠a API REST. Define un endpoint `/predict` que recibe un JSON con un perfil (listas de skills y certificaciones, nivel de seniority, etc.) y devuelve el salario estimado. Internamente carga el modelo entrenado desde `models/` y transforma el perfil de entrada a las features adecuadas (aplicando el mismo esquema de one-hot encoding utilizado en el entrenamiento) antes de generar la predicci√≥n. Permite integrar la predicci√≥n de salario en sistemas externos o consultas automatizadas.
  * `generar_informe.py` ‚Äì Script de **informe de modelado**. Genera un informe PDF que documenta los resultados del modelo de ML: incluye las m√©tricas obtenidas (MAE, etc.), gr√°ficos de desempe√±o comparativo entre algoritmos, e importancia de features basada en SHAP. Utiliza libraries como Matplotlib/Seaborn para graficar y ReportLab/FPDF para la compilaci√≥n del PDF. El informe resultante (ej. `reports/informe_modelado_ml.pdf`) sirve para comunicar a detalle la eficacia del modelo y los factores clave que influyen en el salario.
  * `generar_informe_data_analyst.py` ‚Äì Script de **informe sem√°ntico**. Analiza el texto de las ofertas para extraer insights sobre formaciones y certificaciones. Utiliza *spaCy* para procesar las descripciones y buscar menciones de t√≠tulos universitarios (grado, m√°ster, doctorado) y certificaciones espec√≠ficas, contando su frecuencia. Luego calcula el salario promedio asociado a ofertas que mencionan cada tipo de formaci√≥n. Genera un PDF (ej. `informe_formacion_data_analyst_completo.pdf`) con secciones para cada categor√≠a: por ejemplo, ‚ÄúGrados m√°s solicitados‚Äù con una lista de grados y su frecuencia, ‚ÄúCertificaciones destacadas‚Äù y finalmente una secci√≥n relacionando cada formaci√≥n con el salario medio observado. Incluye gr√°ficas de barras generadas (almacenadas en `img/` temporalmente) para visualizar cu√°les menciones son m√°s comunes. Este informe ofrece una vista resumida y comprensible de qu√© credenciales acad√©micas/profesionales predominan en el mercado y c√≥mo podr√≠an impactar el sueldo.
  * `generador_ruta_formativa.py` ‚Äì Script de **recomendaci√≥n personalizada**. Dado un perfil individual (experiencia, estudios, skills actuales) proporcionado como texto, este m√≥dulo aplica el pipeline completo para asesorar al usuario: primero extrae las skills presentes en el perfil mediante NER, luego utiliza el modelo de salario para estimar el sueldo actual del perfil. A continuaci√≥n, compara las skills del usuario con un conjunto de ‚Äúskills objetivo‚Äù de alta demanda y simula qu√© ocurrir√≠a si el usuario aprendiese esas habilidades que le faltan. Calcula el nuevo salario potencial y el incremento respecto al actual, e imprime una lista de recomendaciones formativas priorizadas (ej. ‚ÄúAprender 'Docker': se observ√≥ correlaci√≥n salarial positiva en las vacantes top‚Äù). Este script, pensado como prueba de concepto, muestra c√≥mo el sistema puede orientar a alguien en qu√© aprender para maximizar su salario, convirtiendo el an√°lisis en consejos accionables.
  * `launcher.py` ‚Äì Script lanzador de la *pipeline* completo. Permite ejecutar en secuencia todos los pasos anteriores de forma automatizada, simplemente ejecutando `python launcher.py`. Internamente llama a `main_pipeline_jobs.py`, luego a `analysis_and_modeling_advanced.py`, seguido de `generar_informe.py` y `generar_informe_data_analyst.py` para producir todos los resultados necesarios. Al finalizar, ofrece la opci√≥n de abrir directamente el dashboard Streamlit. Es √∫til para generar una actualizaci√≥n completa del sistema de una sola vez.
    *Otros archivos notables:* `requirements.txt` (listado de dependencias Python del proyecto con versiones espec√≠ficas), `scrapy.cfg` (configuraci√≥n base de Scrapy), y `instalar_entorno_jobs.ps1` (script PowerShell para configurar entorno virtual e instalar requerimientos en Windows).

## Esquema de Funcionamiento

A grandes rasgos, el flujo de trabajo del sistema ‚Äîdesde la recolecci√≥n de datos hasta la predicci√≥n de salario y visualizaci√≥n‚Äî sigue los siguientes pasos encadenados:

1. **Recolecci√≥n de Datos (Scraping):** Se recopilan las ofertas de empleo para el rol de Analista de Datos desde m√∫ltiples plataformas online. Un spider de Scrapy navega por sitios como LinkedIn, Indeed, Glassdoor, InfoJobs, entre otros, extrayendo de cada oferta campos esenciales: t√≠tulo del puesto, empresa, ubicaci√≥n, rango salarial ofrecido, descripci√≥n del puesto, requisitos, fecha de publicaci√≥n, URL, etc. Toda esta informaci√≥n cruda se almacena en un archivo estructurado (por ejemplo, `data/raw/sample_jobs.csv`). Este paso inicial garantiza una base de datos amplia y actualizada del mercado laboral en ciencia de datos.

2. **Limpieza y Procesamiento NLP:** Los datos brutos del scraping se pasan por un m√≥dulo de limpieza y preprocesamiento textual. Aqu√≠ se eliminan elementos no deseados (etiquetas HTML, s√≠mbolos extra√±os) y se unifican formatos (p.ej., normalizar may√∫sculas). Se detecta el idioma de cada descripci√≥n y, si no est√° en espa√±ol o ingl√©s, se traduce autom√°ticamente para poder aplicar el mismo modelo de lenguaje a todo el corpus. De esta forma, una oferta en alem√°n o franc√©s se traduce al espa√±ol, preservando el sentido pero facilitando la posterior extracci√≥n de entidades. El resultado de este paso son descripciones depuradas y homogeneizadas, listas para la extracci√≥n de informaci√≥n sem√°ntica.

3. **Extracci√≥n y Clasificaci√≥n de Entidades:** A continuaci√≥n, el sistema aplica un modelo de *Named Entity Recognition* (NER) entrenado espec√≠ficamente para este dominio. Este modelo (basado en BERT fine-tuneado) escanea las descripciones de las ofertas y detecta menciones de: **habilidades t√©cnicas** (ej. Python, SQL, Tableau), **herramientas** o softwares, **titulaciones acad√©micas** (Grado, M√°ster, PhD en X), **certificaciones profesionales** (ej. ‚ÄúAWS Certified Solutions Architect‚Äù) e **idiomas** conocidos. Cada entidad reconocida recibe una etiqueta de categor√≠a. Por ejemplo, ‚ÄúData Analysis‚Äù se etiqueta como skill, ‚ÄúM√°ster en Estad√≠stica‚Äù como educaci√≥n, ‚ÄúCertified Scrum Master‚Äù como certificaci√≥n. Gracias a esta clasificaci√≥n, transformamos el texto libre de la oferta en informaci√≥n estructurada sobre qu√© *skills* y credenciales exige o valora cada empleo.

4. **Construcci√≥n del Dataset Estructurado:** Con las entidades extra√≠das de cada oferta, se construye un dataset tabular consolidado. Cada fila del dataset representa una oferta de trabajo e incluye:

   * **Features binarias:** columnas indicadoras (0/1) de la presencia de cada skill relevante, cada certificaci√≥n importante, cada idioma, etc. Por ejemplo, una columna `skill_Python` vale 1 si la oferta menciona Python. De igual modo `certificaci√≥n_CFA` valdr√≠a 1 si se pide la certificaci√≥n CFA.
   * **Variables num√©ricas y categ√≥ricas contextuales:** se incorporan columnas como nivel de seniority del puesto (junior/medio/senior), sector de la empresa (tecnolog√≠a, finanzas, etc.), ubicaci√≥n geogr√°fica o incluso tama√±o de la empresa, siempre que esos datos est√©n disponibles o se puedan inferir de la oferta. El salario ofrecido se normaliza a una cifra anual bruta en euros para usar como variable *target*. Si una oferta solo daba un rango (m√≠n-m√°x), se calcula el promedio del rango como estimaci√≥n.
   * **Features derivadas del texto:** adicionalmente, se pueden a√±adir indicadores como la longitud de la descripci√≥n, conteo de requisitos mencionados, o puntuaciones de similitud con perfiles tipo, aunque el foco principal son las variables anteriores.

   El resultado es un *dataset* listo para ML donde cada columna tiene significado claro (presencia de X skill, tiene Y certificaci√≥n, etc.) y la √∫ltima columna es el salario (num√©rico) asociado. Este dataset es el puente que conecta el lenguaje de las ofertas con algoritmos de predicci√≥n cuantitativos.

5. **Modelado Predictivo del Salario:** Usando el dataset estructurado, el sistema entrena modelos de Machine Learning supervisados para predecir el salario en funci√≥n de las caracter√≠sticas de cada oferta. Se divide el dataset en entrenamiento/validaci√≥n y se prueban varios algoritmos: desde √°rboles de decisi√≥n ensamblados (Random Forest, XGBoost, LightGBM, CatBoost) hasta redes neuronales profundas. Cada modelo se optimiza mediante validaci√≥n cruzada y b√∫squeda de hiperpar√°metros (por ejemplo, ajustando la profundidad de los √°rboles, learning rate, n√∫mero de neuronas, etc.). El mejor modelo alcanz√≥ un **MAE inferior al 5 %**, lo que implica que, en promedio, la diferencia entre el salario predicho y el real es menor al 5 %. Para aumentar la robustez, se ensambla un modelo final combinando los m√°s precisos (t√©cnica de *stacking*), y ese ensemble es el que se conserva para producci√≥n. Al final de esta fase, tenemos un modelo entrenado que, dada la ‚Äúfirma‚Äù de skills y formaciones de una oferta, puede estimar su salario con alta precisi√≥n.

6. **Evaluaci√≥n e Interpretabilidad:** Con el modelo entrenado, se eval√∫a su desempe√±o en un conjunto de prueba o mediante *cross-validation*. Se confirman m√©tricas como el MAE mencionado y se verifica que el modelo no est√© sobreajustado (por ejemplo, comparando error en train vs. test). Luego se realiza un an√°lisis de **importancia de caracter√≠sticas** para entender el modelo: se emplea SHAP para calcular cu√°nto aporta cada feature a la predicci√≥n de salario. Por ejemplo, SHAP puede revelar que tener la skill ‚ÄúAWS‚Äù suma, digamos, 5.000 ‚Ç¨ al salario esperado, mientras que no tener ‚ÄúExcel‚Äù podr√≠a restar 2.000 ‚Ç¨. Se genera un ranking de las variables m√°s influyentes globalmente en el modelo y tambi√©n se pueden explicar casos individuales. Esta interpretabilidad es crucial para validar que el modelo se comporta de forma intuitiva (ej., skills de *machine learning* efectivamente empujan el salario hacia arriba) y para extraer insights accionables de los datos.

7. **Visualizaci√≥n y Reporte de Resultados:** Los insights obtenidos se comunican a trav√©s de dos canales principales:

   * **Dashboard Interactivo:** Una aplicaci√≥n web desarrollada con Streamlit permite a usuarios finales interactuar con los datos y el modelo sin necesidad de programar. En este dashboard, se puede filtrar las ofertas por cualquier combinaci√≥n de habilidades, certificaciones o estudios desde una barra lateral. En tiempo real, la aplicaci√≥n muestra cu√°ntas ofertas cumplen esos criterios y recalcula la distribuci√≥n de sus salarios, dibujando histogramas actualizados. Tambi√©n lista las top 10 skills/certificaciones m√°s frecuentes en el subconjunto filtrado, para ver qu√© es com√∫n entre las ofertas seleccionadas. Esto permite responder a preguntas como ‚Äú¬øCu√°l es el rango salarial de puestos que requieren Python y SQL pero no piden t√≠tulo de m√°ster?‚Äù de forma visual e inmediata.
   * **Informes Autom√°ticos:** Se generan informes en PDF de manera programada que condensan los hallazgos del an√°lisis para un p√∫blico m√°s amplio. Un informe resume, por ejemplo, *‚ÄúTop 5 certificaciones para Analistas de Datos y su salario medio‚Äù* o *‚ÄúComparativa de salario seg√∫n nivel acad√©mico‚Äù*. Incluye gr√°ficos de barras mostrando la frecuencia de cada grado universitario en las ofertas analizadas y el salario promedio correspondiente a ofertas que mencionan cada grado. Otro informe detalla las m√©tricas de los modelos y destaca, con texto y gr√°ficos, qu√© variables explicativas tienen mayor peso en el modelo predictivo. Estos informes se pueden distribuir al equipo de RRHH o a interesados, brindando una visi√≥n ejecutiva del an√°lisis sin necesidad de interactuar con el dashboard.

8. **Predicci√≥n y Recomendaci√≥n Personalizada:** Finalmente, el sistema permite utilizar el modelo de forma inversa para orientar a profesionales individuales. A trav√©s de la **API REST** o del script espec√≠fico de ruta formativa, un usuario ingresa su perfil (sus habilidades actuales, certificaciones obtenidas, experiencia, etc.) y el sistema predice cu√°l ser√≠a su salario en el mercado con ese perfil. M√°s importante a√∫n, el sistema identifica qu√© le **falta** al perfil para alcanzar salarios m√°s altos: compara las skills del usuario con las skills top demandadas en las ofertas mejor pagadas. Por ejemplo, puede descubrir que al usuario le faltan ‚ÄúDocker‚Äù y ‚ÄúAWS‚Äù que son muy valoradas. Entonces simula que el usuario aprende esas habilidades y recalcula un salario ‚Äúpotencial‚Äù si el perfil las tuviera. Si el salario sube significativamente (digamos +15%), eso indica un alto ROI en aprender dicha skill. El resultado para el usuario es una **recomendaci√≥n formativa personalizada**: una lista priorizada de nuevas skills o certificaciones a adquirir para maximizar su sueldo futuro, indicando en cu√°nto podr√≠a aumentar su remuneraci√≥n al completar cada formaci√≥n. Este esquema cierra el c√≠rculo del proyecto, aplicando el conocimiento extra√≠do del mercado directamente en consejos accionables para el desarrollo profesional individual.

## üåü Propuestas para Mejorar y Escalar el Proyecto

* **Robustecer y Escalar el *Scraping*:** Implementar mayor tolerancia a fallos en la recolecci√≥n de datos. Por ejemplo, a√±adir reintentos y manejo de excepciones en los spiders para que un bloqueo temporal o cambio en la estructura HTML de una web no detenga el pipeline completo. Usar rotaci√≥n de proxies y *user agents* para minimizar el riesgo de bloqueos por parte de las plataformas objetivo. Adem√°s, paralelizar el scraping (ejecutando m√∫ltiples spiders en simult√°neo o distribuyendo el trabajo en varios contenedores) permitir√≠a actualizar el dataset con mayor frecuencia. Integrar APIs oficiales de empleo (cuando existan, p. ej. la API de LinkedIn Jobs) podr√≠a suplementar o reemplazar el scraping manual, obteniendo datos m√°s limpios y ricos (aunque esto podr√≠a requerir acuerdos o keys de API). Mantener un **cronograma de scraping** automatizado (por ejemplo con Airflow o un cron job en la nube) garantizar√° que el modelo siempre entrene con datos recientes, capturando nuevas tecnolog√≠as o tendencias salariales en cuanto aparezcan.

* **Enriquecimiento del Preprocesamiento NLP:** Mejorar la detecci√≥n de entidades entrenando el modelo NER con un corpus m√°s amplio y espec√≠fico del dominio (por ejemplo, utilizando descripciones de ofertas hist√≥ricas para etiquetar y aprender variaciones inusuales de nombrar skills/herramientas). Implementar reglas de *matching* o diccionarios auxiliares para complementar al modelo en casos de siglas o nombres muy espec√≠ficos (ej. asegurarse de reconocer siglas como ‚ÄúGDP‚Äù o ‚ÄúETL‚Äù como skills). La *desambiguaci√≥n sem√°ntica* puede refinarse aplicando clustering sobre los embeddings de las entidades extra√≠das: as√≠, t√©rminos equivalentes (Big Data vs. ‚Äúdatos masivos‚Äù) se agrupan autom√°ticamente. Estas t√©cnicas ayudan a que las features generadas sean m√°s consistentes y reduzcan el ruido en el modelo. Tambi√©n ser√≠a √∫til expandir la l√≥gica de categorizaci√≥n: actualmente se separan skills, certs, educaci√≥n, idiomas, pero podr√≠an a√±adirse categor√≠as como *metodolog√≠as* (ej. Agile, Scrum) o *herramientas de negocio* (Salesforce, SAP) si aparecen con frecuencia, asegurando que cualquier tipo de requisito importante est√© siendo capturado adecuadamente. Por √∫ltimo, extender el soporte multiling√ºe: si bien ahora se traduce todo al espa√±ol/ingl√©s, en futuros desarrollos el modelo podr√≠a ser directamente multiling√ºe o entrenarse una versi√≥n NER por idioma para conservar matices y detectar entidades con m√°s precisi√≥n en la lengua original.

* **Mejoras en el Modelo Predictivo:** Aunque el desempe√±o actual es alto, siempre se puede iterar. Se podr√≠a probar un **modelo de ensemble m√°s diverso**, combinando no solo algoritmos tipo √°rbol sino tambi√©n modelos lineales o de Deep Learning en el stacking final, para capturar diferentes relaciones en los datos. Otra idea es incorporar **variables macroecon√≥micas** o externas en el modelo, por ejemplo √≠ndices de costo de vida por ciudad (para ajustar salarios seg√∫n ubicaci√≥n) o la demanda general de una skill en el mercado (lo cual podr√≠a obtenerse de la frecuencia de aparici√≥n de esa skill en las ofertas totales). Asimismo, implementar t√©cnicas de *feature selection* o generaci√≥n de nuevas features (por ejemplo, contar cu√°ntas skills distintas pide cada oferta como indicador de amplitud del rol) podr√≠a mejorar la explicaci√≥n de la variabilidad salarial. En t√©rminos de entrenamiento, podr√≠a utilizarse **validaci√≥n temporal** si los datos abarcan varios meses/a√±os, de modo que el modelo aprenda tendencias temporales (ej. salarios crecientes anualmente) y sea capaz de predecir en el futuro inmediato con mayor acierto. Por √∫ltimo, para mayor robustez en producci√≥n, se puede entrenar un **modelo ligero de reserva** (por ejemplo un regresor lineal simple) que se active si el modelo principal falla o si se recibe un perfil con muchas caracter√≠sticas fuera del rango conocido, garantizando siempre alguna predicci√≥n razonable.

* **Optimizaci√≥n de la Interpretabilidad:** Integrar de forma m√°s visible las explicaciones del modelo en las herramientas de usuario. Por ejemplo, enriquecer el dashboard para que cuando el usuario consulte un perfil simulado, no solo se le d√© un n√∫mero de salario, sino tambi√©n un desglose de *‚Äúestas 3 habilidades de tu perfil aportan +10k‚Ç¨, pero te penaliza no tener tal master (-5k‚Ç¨)‚Äù*. Esto podr√≠a implementarse mostrando los valores SHAP locales para ese perfil de entrada, en un gr√°fico de barras sencillo dentro de la app. Tambi√©n se pueden pre-calcular an√°lisis m√°s globales, como *‚ÄúTop 5 skills emergentes‚Äù* definidas como aquellas cuya ausencia resta mucho salario pero que pocos candidatos poseen, para orientar iniciativas de formaci√≥n a nivel macro. Adicionalmente, se podr√≠an usar t√©cnicas como *Partial Dependence Plots* o *ICE (Individual Conditional Expectation)* en el dashboard para que un usuario explore c√≥mo cambiar√≠a el salario si ajusta una caracter√≠stica a la vez (what-if analysis), complementando la simulaci√≥n multivariable que ya se hace en la recomendaci√≥n personalizada.

* **Ampliaci√≥n del Sistema de Recomendaci√≥n:** Para llevar la recomendaci√≥n formativa al siguiente nivel, incorporar datos de **costos y duraci√≥n de formaciones**. Por ejemplo, si sabemos que una certificaci√≥n de AWS cuesta X ‚Ç¨ y requiere Y horas de estudio, el sistema podr√≠a calcular el tiempo de recuperaci√≥n de la inversi√≥n dado el aumento salarial esperado. Esto permitir√≠a priorizar no solo por impacto en salario sino por eficiencia (ROI real en t√©rminos monetarios y de esfuerzo). Asimismo, se podr√≠a enlazar con fuentes de cursos o programas espec√≠ficos: tras recomendar ‚Äúaprende Docker‚Äù, el sistema podr√≠a sugerir directamente cursos en Coursera, Udemy, o m√°sters relevantes, idealmente usando APIs o scraping de esas plataformas educativas para obtener los cursos mejor evaluados relacionados con Docker. Otra mejora ser√≠a personalizar las recomendaciones seg√∫n el punto de partida del usuario: no es lo mismo sugerir ‚Äúaprende Machine Learning‚Äù a alguien que ya es fuerte en programaci√≥n que a alguien que viene de un rol m√°s de negocio; una integraci√≥n con un sistema de evaluaci√≥n de nivel podr√≠a refinar las rutas formativas (ofreciendo quiz√°s pasos previos antes de abordar ciertas skills avanzadas). Finalmente, conforme el sistema acumule datos de usuarios y sus progresos, se podr√≠a implementar un m√≥dulo de *feedback loop*: si varios usuarios siguieron cierta recomendaci√≥n y lograron aumentos salariales, el sistema puede destacar a√∫n m√°s esa ruta; en cambio, si alguna certificaci√≥n no estuvo correlacionando con mejoras reales, quiz√°s bajarla de prioridad. Esto convertir√≠a la plataforma en una especie de *recomendador vivo* de desarrollo profesional.

* **Mejoras en la Arquitectura y MLOps:** Actualmente el proyecto es funcional, pero de cara a producci√≥n real conviene hacerlo m√°s modular y mantenible. Separar claramente los componentes en servicios independientes: por ejemplo, un microservicio dedicado al scraping, otro a las predicciones, y otro sirviendo el dashboard. Estos podr√≠an orquestarse con Kubernetes, lo que permitir√≠a escalar cada componente seg√∫n la carga (ej., escalar horizontalmente el scraper durante una actualizaci√≥n masiva de datos, o el API en horas pico de consultas). Implementar un registro de modelos con MLflow u otro equivalente facilitar√≠a llevar control de versiones de modelo: cada vez que se reentrena, se podr√≠a guardar el nuevo modelo con un ID √∫nico, sus m√©tricas y artefactos, y quiz√°s activar un *canary deployment* donde un porcentaje peque√±o de predicciones usen el nuevo modelo para monitorear su desempe√±o antes de un cambio completo. En cuanto a CI/CD, adem√°s de pruebas unitarias al c√≥digo, se podr√≠an incluir *tests de datos* (por ejemplo, verificar que despu√©s del scraping el n√∫mero de ofertas no es anormalmente bajo, o que el formato de los salarios sigue una regla esperada) para detectar autom√°ticamente problemas aguas arriba. Tambi√©n ser√≠a beneficioso integrar herramientas de an√°lisis de calidad de datos como Great Expectations para asegurarse de que el dataset de entrenamiento cumple ciertos criterios antes de lanzar el modelado. En resumen, adoptar principios de **ingenier√≠a de datos y MLOps** m√°s estrictos har√≠a el proyecto m√°s **robusto** ante cambios y m√°s f√°cil de escalar o transferir a un entorno de producci√≥n corporativa.

* **Refinamiento de la Estructura de C√≥digo:** A nivel c√≥digo, se pueden introducir mejoras para claridad y extensibilidad. Por ejemplo, convertir los scripts en un paquete Python instalable (`formacion_salarial_ai`), de modo que funciones como `procesar_datos()` o `entrenar_modelo()` puedan importarse y reutilizarse en lugar de duplicar l√≥gica entre scripts. Esto facilitar√≠a escribir nuevos scripts o notebooks que aprovechen partes del pipeline sin copiarlas. A√±adir **tipado est√°tico** con Python *type hints* en funciones cr√≠ticas (por ej. qu√© tipo de dataframe esperan/devuelven) ayuda a el mantenimiento y a evitar ciertos bugs. Asimismo, aumentar la documentaci√≥n: incluir en el README ejemplos de uso de la API (ej. un comando curl para probar la predicci√≥n REST) o instrucciones para desplegar en cloud. En el c√≥digo, a√±adir docstrings que expliquen las clases y m√©todos, por qu√© se toman ciertas decisiones (e.g., ‚Äúusamos medianas para salarios rangos porque‚Ä¶‚Äù), de modo que nuevos contribuidores entiendan r√°pidamente el flujo. Implementar un conjunto de **pruebas automatizadas** m√≠nimo (unittest/pytest) para las funciones de transformaci√≥n de datos y de predicci√≥n garantizar√° que futuras modificaciones no rompan la compatibilidad (por ejemplo, testear que `parse_salary("$50,000-$60,000")` devuelve correctamente \~55000). Aunque al inicio de un proyecto pueda parecer innecesario, a medida que crece en complejidad estas pr√°cticas de ingenier√≠a asegurar√°n m√°xima confiabilidad y facilidad de evoluci√≥n.

* **Integraci√≥n de IA Generativa (LLM) como Capacidad Adicional:** Una mejora innovadora ser√≠a incorporar un modelo de lenguaje grande (por ejemplo GPT-4) para interactuar con usuarios y con los datos de forma m√°s *inteligente*. Imaginemos un **chatbot formativo** integrado en el dashboard: un usuario podr√≠a preguntarle en espa√±ol *‚Äú¬øQu√© diferencia salarial hay entre saber Python vs R para un analista de datos?‚Äù* y el chatbot, apoy√°ndose en el dataset (quiz√° mediante embeddings en un vector store) podr√≠a responder *‚ÄúEn promedio, las ofertas que mencionan Python ofrecen un 8% m√°s de salario que las que mencionan R, aunque muchos roles piden ambos.‚Äù*. Este mismo chatbot podr√≠a guiar al usuario a trav√©s de su perfil profesional en lenguaje natural, realizando un *assessment* conversacional y luego enlazando con el m√≥dulo de recomendaci√≥n para ofrecerle un plan de acci√≥n. T√©cnicamente, esto implica alimentar al LLM con contexto relevante (ej. estad√≠sticas precomputadas, o permitirle hacer consultas al modelo de predicci√≥n para casos hipot√©ticos) manteniendo seguridad y costos controlados. Otra integraci√≥n posible de IA generativa es en la faceta de **procesamiento de texto**: usar modelos como GPT para resumir descripciones demasiado largas de ofertas o para traducir con mayor calidad y matices podr√≠a complementar al pipeline actual. Estas adiciones har√≠an el sistema a√∫n m√°s atractivo y *user-friendly*, combinando an√°lisis de datos riguroso con una interfaz conversacional inteligente.

En conjunto, **estas mejoras apuntan a un sistema m√°s avanzado, preciso y robusto**, capaz de adaptarse a nuevos desaf√≠os. Al implementar gradualmente estas propuestas, la plataforma podr√≠a consolidarse como una herramienta de referencia en la planificaci√≥n de desarrollo profesional en ciencia de datos, escalable a otros roles e incluso otros dominios, manteniendo siempre un enfoque en la calidad de los datos y la fiabilidad de las predicciones.
